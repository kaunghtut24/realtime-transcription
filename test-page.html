<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AssemblyAI Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
            font-weight: bold;
        }
        .status.idle { background-color: #e3f2fd; color: #1976d2; }
        .status.connecting { background-color: #fff3e0; color: #f57c00; }
        .status.connected { background-color: #e8f5e8; color: #388e3c; }
        .status.error { background-color: #ffebee; color: #d32f2f; }
        .status.closed { background-color: #f3e5f5; color: #7b1fa2; }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
        }
        .start-btn { background-color: #4caf50; color: white; }
        .stop-btn { background-color: #f44336; color: white; }
        .test-btn { background-color: #2196f3; color: white; }
        .transcript {
            background-color: #f9f9f9;
            padding: 15px;
            border-radius: 4px;
            margin: 10px 0;
            min-height: 100px;
        }
        .log {
            background-color: #263238;
            color: #b0bec5;
            padding: 15px;
            border-radius: 4px;
            font-family: monospace;
            font-size: 12px;
            max-height: 300px;
            overflow-y: auto;
            white-space: pre-wrap;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è AssemblyAI Universal Streaming Test</h1>
        
        <div class="controls">
            <button class="test-btn" onclick="testConnection()">Test Token Endpoint</button>
            <button class="start-btn" onclick="startRecording()">Start Recording</button>
            <button class="stop-btn" onclick="stopRecording()">Stop Recording</button>
        </div>
        
        <div id="status" class="status idle">Status: Idle</div>
        
        <div class="transcript">
            <h3>Transcript:</h3>
            <div id="transcript">No transcript yet...</div>
        </div>
        
        <div class="log">
            <h3>Console Log:</h3>
            <div id="log"></div>
        </div>
    </div>

    <script>
        const API_KEY = '1bf78c53d52f48749e49885158b002bc'; // Your AssemblyAI API key
        const API_URL = 'http://localhost:3001/api';
        
        let ws = null;
        let audioStream = null;
        let audioContext = null;
        let audioWorkletNode = null;
        let audioBuffer = [];
        let bufferSendInterval = null;
        
        function log(message) {
            console.log(message);
            const logDiv = document.getElementById('log');
            logDiv.textContent += new Date().toLocaleTimeString() + ': ' + message + '\n';
            logDiv.scrollTop = logDiv.scrollHeight;
        }
        
        function updateStatus(status, className) {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = 'Status: ' + status;
            statusDiv.className = 'status ' + className;
        }
        
        async function testConnection() {
            log('Testing token endpoint...');
            
            try {
                const response = await fetch(`${API_URL}/assemblyai/token`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': API_KEY
                    },
                    body: JSON.stringify({ expires_in_seconds: 600 })
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                
                const data = await response.json();
                log('‚úÖ Token received: ' + data.token.substring(0, 50) + '...');
                log('‚úÖ Expires in ' + data.expires_in_seconds + ' seconds');
                
                // Test WebSocket connection
                await testWebSocket(data.token);
                
            } catch (error) {
                log('‚ùå Token test failed: ' + error.message);
            }
        }
        
        async function testWebSocket(token) {
            log('Testing WebSocket connection...');
            
            const params = new URLSearchParams({
                token: token,
                sample_rate: '16000',
                encoding: 'pcm_s16le',
                format_turns: 'true'
            });
            
            const wsUrl = `wss://streaming.assemblyai.com/v3/ws?${params.toString()}`;
            const testWs = new WebSocket(wsUrl);
            
            testWs.onopen = () => {
                log('‚úÖ WebSocket connected successfully!');
                setTimeout(() => {
                    testWs.close();
                }, 2000);
            };
            
            testWs.onmessage = (event) => {
                const message = JSON.parse(event.data);
                log('üì® Received: ' + JSON.stringify(message));
            };
            
            testWs.onerror = (error) => {
                log('‚ùå WebSocket error: ' + error);
            };
            
            testWs.onclose = (event) => {
                log('üîí WebSocket closed: ' + event.code + ' ' + event.reason);
            };
        }
        
        async function startRecording() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                log('Already recording');
                return;
            }
            
            log('Starting recording...');
            updateStatus('Connecting', 'connecting');
            
            try {
                // Get token
                const tokenResponse = await fetch(`${API_URL}/assemblyai/token`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': API_KEY
                    },
                    body: JSON.stringify({ expires_in_seconds: 600 })
                });
                
                if (!tokenResponse.ok) {
                    throw new Error('Failed to get token');
                }
                
                const { token } = await tokenResponse.json();
                log('Token received');
                
                // Get microphone access
                audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                log('Microphone access granted');
                
                // Setup WebSocket
                const params = new URLSearchParams({
                    token: token,
                    sample_rate: '16000',
                    encoding: 'pcm_s16le',
                    format_turns: 'true'
                });
                
                ws = new WebSocket(`wss://streaming.assemblyai.com/v3/ws?${params.toString()}`);
                
                ws.onopen = async () => {
                    log('WebSocket connected');
                    updateStatus('Connected', 'connected');
                    await setupAudio();
                };
                
                ws.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    log('Received: ' + message.type);
                    
                    if (message.type === 'Turn') {
                        document.getElementById('transcript').textContent = message.transcript;
                    } else if (message.type === 'Begin') {
                        log('Session started: ' + message.id);
                    }
                };
                
                ws.onerror = (error) => {
                    log('WebSocket error: ' + error);
                    updateStatus('Error', 'error');
                };
                
                ws.onclose = (event) => {
                    log('WebSocket closed: ' + event.code);
                    updateStatus('Closed', 'closed');
                    cleanup();
                };
                
            } catch (error) {
                log('Failed to start recording: ' + error.message);
                updateStatus('Error', 'error');
            }
        }
        
        async function setupAudio() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            const workletCode = `
                class RecorderProcessor extends AudioWorkletProcessor {
                    constructor() {
                        super();
                        this.targetSampleRate = 16000;
                    }
                    
                    process(inputs) {
                        const inputChannelData = inputs[0][0];
                        if (!inputChannelData) return true;
                        
                        const sourceSampleRate = sampleRate;
                        const downsampleRatio = sourceSampleRate / this.targetSampleRate;
                        const outputLength = Math.floor(inputChannelData.length / downsampleRatio);
                        const resampledData = new Float32Array(outputLength);
                        
                        for (let i = 0; i < outputLength; i++) {
                            const sourceIndex = Math.floor(i * downsampleRatio);
                            resampledData[i] = inputChannelData[sourceIndex];
                        }
                        
                        const pcm16 = new Int16Array(resampledData.length);
                        for (let i = 0; i < resampledData.length; i++) {
                            let s = Math.max(-1, Math.min(1, resampledData[i]));
                            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        
                        if (pcm16.length > 0) {
                            this.port.postMessage(pcm16.buffer, [pcm16.buffer]);
                        }
                        return true;
                    }
                }
                registerProcessor('recorder-processor', RecorderProcessor);
            `;
            
            const workletURL = URL.createObjectURL(new Blob([workletCode], { type: 'application/javascript' }));
            await audioContext.audioWorklet.addModule(workletURL);
            URL.revokeObjectURL(workletURL);
            
            const source = audioContext.createMediaStreamSource(audioStream);
            audioWorkletNode = new AudioWorkletNode(audioContext, 'recorder-processor');
            
            audioWorkletNode.port.onmessage = (event) => {
                const pcmData = new Int16Array(event.data);
                audioBuffer.push(pcmData);
                
                const totalSamples = audioBuffer.reduce((sum, b) => sum + b.length, 0);
                if (totalSamples >= 800) { // 50ms at 16kHz
                    sendAudioBuffer();
                }
            };
            
            source.connect(audioWorkletNode);
            
            bufferSendInterval = setInterval(sendAudioBuffer, 200);
            log('Audio processing started');
        }
        
        function sendAudioBuffer() {
            if (audioBuffer.length === 0 || !ws || ws.readyState !== WebSocket.OPEN) {
                return;
            }
            
            const totalLength = audioBuffer.reduce((sum, b) => sum + b.length, 0);
            if (totalLength < 800) return; // Need at least 50ms
            
            const concatenated = new Int16Array(totalLength);
            let offset = 0;
            for (const buffer of audioBuffer) {
                concatenated.set(buffer, offset);
                offset += buffer.length;
            }
            
            ws.send(concatenated.buffer);
            audioBuffer = [];
            log('Sent ' + totalLength + ' samples');
        }
        
        function stopRecording() {
            log('Stopping recording...');
            updateStatus('Closing', 'closing');
            
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "Terminate" }));
            }
            
            cleanup();
        }
        
        function cleanup() {
            if (bufferSendInterval) {
                clearInterval(bufferSendInterval);
                bufferSendInterval = null;
            }
            
            if (audioWorkletNode) {
                audioWorkletNode.disconnect();
                audioWorkletNode = null;
            }
            
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
                audioContext = null;
            }
            
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            
            if (ws) {
                ws.close();
                ws = null;
            }
            
            audioBuffer = [];
            updateStatus('Idle', 'idle');
            log('Cleanup completed');
        }
    </script>
</body>
</html>
